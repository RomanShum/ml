{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### О задании\n",
    "\n",
    "Практическое задание 1 посвящено изучению основных библиотек для анализа данных, а также линейных моделей и методов их обучения. Вы научитесь:\n",
    " * применять библиотеки NumPy и Pandas для осуществления желаемых преобразований;\n",
    " * подготавливать данные для обучения линейных моделей;\n",
    " * обучать линейную, Lasso и Ridge-регрессии при помощи модуля scikit-learn;\n",
    " * реализовывать обычный и стохастический градиентные спуски;\n",
    " * обучать линейную регрессию для произвольного функционала качества.\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Библиотеки для анализа данных\n",
    "\n",
    "### NumPy\n",
    "\n",
    "Во всех заданиях данного раздела запрещено использовать циклы  и list comprehensions. Под вектором и матрицей в данных заданиях понимается одномерный и двумерный numpy.array соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Реализуйте функцию, возвращающую максимальный элемент в векторе x среди элементов, перед которыми стоит нулевой. Для x = np.array([6, 2, 0, 3, 0, 0, 5, 7, 0]) ответом является 5. Если нулевых элементов нет, функция должна возвращать None.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def max_element(arr):\n",
    "    zero = arr==0\n",
    "    try: \n",
    "        return arr[1:][zero[:-1]].max()\n",
    "    except ValueError:\n",
    "        return None \n",
    "max_element(np.array([6, 2, 0, 3, 0, 0, 5, 7, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. ** Реализуйте функцию, принимающую на вход матрицу и некоторое число и возвращающую ближайший к числу элемент матрицы. Например: для X = np.arange(0,10).reshape((2, 5)) и v = 3.6 ответом будет 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nearest_value(X, v):\n",
    "    func = np.vectorize(lambda x: abs(x-v))\n",
    "    delta = func(X)\n",
    "    index_min = np.argmin(delta)\n",
    "    return X[index_min]\n",
    "\n",
    "nearest_value(np.arange(0,10), 3.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. ** Реализуйте функцию scale(X), которая принимает на вход матрицу и масштабирует каждый ее столбец (вычитает выборочное среднее и делит на стандартное отклонение). Убедитесь, что в функции не будет происходить деления на ноль. Протестируйте на случайной матрице (для её генерации можно использовать, например, функцию [numpy.random.randint](http://docs.scipy.org/doc/numpy/reference/generated/numpy.random.randint.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9  7]\n",
      " [11  4]\n",
      " [13  6]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.22474487,  1.06904497],\n",
       "       [ 0.        , -1.33630621],\n",
       "       [ 1.22474487,  0.26726124]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scale(X):\n",
    "    mean = np.mean(X, axis=0)\n",
    "    var = np.std(X, axis=0)\n",
    "    if 0 not in var:\n",
    "        return (X - mean)/var\n",
    "    \n",
    "X = np.random.randint(0, 15, (3, 2))\n",
    "print(X)\n",
    "scale(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** Реализуйте функцию, которая для заданной матрицы находит:\n",
    " - определитель\n",
    " - след\n",
    " - наименьший и наибольший элементы\n",
    " - норму Фробениуса\n",
    " - собственные числа\n",
    " - обратную матрицу\n",
    "\n",
    "Для тестирования сгенерируйте матрицу с элементами из нормального распределения $\\mathcal{N}$(10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-20.211969000946066,\n",
       " 28.43265184087179,\n",
       " 12.168452551941966,\n",
       " 8.752849213348652,\n",
       " 30.19332367681371,\n",
       " array([29.97979381,  0.35452407, -1.90166605]),\n",
       " array([[ 1.83210086, -0.94473578, -0.98216814],\n",
       "        [-0.2462469 , -0.10939055,  0.39300121],\n",
       "        [-1.59313675,  1.15011965,  0.60547373]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_stats(X):\n",
    "    return (np.linalg.det(X), np.trace(X), np.amax(X), np.amin(X), np.linalg.norm(X), np.linalg.eig(X)[0], np.linalg.inv(X))\n",
    "X = np.random.normal(10, 1, (3, 3))\n",
    "get_stats(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.** Повторите 100 раз следующий эксперимент: сгенерируйте две матрицы размера 10×10 из стандартного нормального распределения, перемножьте их (как матрицы) и найдите максимальный элемент. Какое среднее значение по экспериментам у максимальных элементов? 95-процентная квантиль?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3325366545326087\n",
      "-20.20718270174468\n"
     ]
    }
   ],
   "source": [
    "max = []\n",
    "for exp_num in range(100):\n",
    "    f = np.random.normal(0, 1, 100)\n",
    "    t = np.random.normal(0, 1, 100)\n",
    "    max += [np.amax(f.dot(t))]\n",
    "    \n",
    "print(np.mean(max))\n",
    "\n",
    "print(np.percentile(max, 0.95))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas\n",
    "\n",
    "![](https://metrouk2.files.wordpress.com/2015/10/panda.jpg)\n",
    "\n",
    "#### Ответьте на вопросы о данных по авиарейсам в США за январь-апрель 2008 года.\n",
    "\n",
    "[Данные](https://www.dropbox.com/s/dvfitn93obn0rql/2008.csv?dl=0) и их [описание](http://stat-computing.org/dataexpo/2009/the-data.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>ArrTime</th>\n",
       "      <th>CRSArrTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>FlightNum</th>\n",
       "      <th>...</th>\n",
       "      <th>TaxiIn</th>\n",
       "      <th>TaxiOut</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>CancellationCode</th>\n",
       "      <th>Diverted</th>\n",
       "      <th>CarrierDelay</th>\n",
       "      <th>WeatherDelay</th>\n",
       "      <th>NASDelay</th>\n",
       "      <th>SecurityDelay</th>\n",
       "      <th>LateAircraftDelay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>2111.0</td>\n",
       "      <td>2055</td>\n",
       "      <td>2308.0</td>\n",
       "      <td>2300</td>\n",
       "      <td>WN</td>\n",
       "      <td>242</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1426.0</td>\n",
       "      <td>1410</td>\n",
       "      <td>1730.0</td>\n",
       "      <td>1728</td>\n",
       "      <td>XE</td>\n",
       "      <td>2380</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1143.0</td>\n",
       "      <td>1145</td>\n",
       "      <td>1501.0</td>\n",
       "      <td>1520</td>\n",
       "      <td>WN</td>\n",
       "      <td>1769</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>1141.0</td>\n",
       "      <td>1144</td>\n",
       "      <td>1323.0</td>\n",
       "      <td>1335</td>\n",
       "      <td>OO</td>\n",
       "      <td>3802</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>815.0</td>\n",
       "      <td>820</td>\n",
       "      <td>1243.0</td>\n",
       "      <td>1300</td>\n",
       "      <td>WN</td>\n",
       "      <td>399</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>2008</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1829.0</td>\n",
       "      <td>1840</td>\n",
       "      <td>2137.0</td>\n",
       "      <td>2149</td>\n",
       "      <td>DL</td>\n",
       "      <td>794</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>2008</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>1149.0</td>\n",
       "      <td>1125</td>\n",
       "      <td>1336.0</td>\n",
       "      <td>1314</td>\n",
       "      <td>OO</td>\n",
       "      <td>6159</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>2008</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>1012</td>\n",
       "      <td>1132.0</td>\n",
       "      <td>1132</td>\n",
       "      <td>YV</td>\n",
       "      <td>7058</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1906.0</td>\n",
       "      <td>1900</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>2139</td>\n",
       "      <td>NW</td>\n",
       "      <td>641</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>859.0</td>\n",
       "      <td>900</td>\n",
       "      <td>959.0</td>\n",
       "      <td>1005</td>\n",
       "      <td>WN</td>\n",
       "      <td>510</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year  Month  DayofMonth  DayOfWeek  DepTime  CRSDepTime  ArrTime  \\\n",
       "0      2008      6          18          3   2111.0        2055   2308.0   \n",
       "1      2008      6           4          3   1426.0        1410   1730.0   \n",
       "2      2008      8           3          7   1143.0        1145   1501.0   \n",
       "3      2008      1          23          3   1141.0        1144   1323.0   \n",
       "4      2008      5           4          7    815.0         820   1243.0   \n",
       "...     ...    ...         ...        ...      ...         ...      ...   \n",
       "69995  2008      5          12          1   1829.0        1840   2137.0   \n",
       "69996  2008      5          11          7   1149.0        1125   1336.0   \n",
       "69997  2008      9          24          3   1012.0        1012   1132.0   \n",
       "69998  2008      2          18          1   1906.0        1900   2200.0   \n",
       "69999  2008     12           6          6    859.0         900    959.0   \n",
       "\n",
       "       CRSArrTime UniqueCarrier  FlightNum  ... TaxiIn  TaxiOut  Cancelled  \\\n",
       "0            2300            WN        242  ...    3.0      8.0          0   \n",
       "1            1728            XE       2380  ...    4.0     12.0          0   \n",
       "2            1520            WN       1769  ...    4.0      9.0          0   \n",
       "3            1335            OO       3802  ...    4.0     19.0          0   \n",
       "4            1300            WN        399  ...    4.0      8.0          0   \n",
       "...           ...           ...        ...  ...    ...      ...        ...   \n",
       "69995        2149            DL        794  ...   22.0     20.0          0   \n",
       "69996        1314            OO       6159  ...    4.0     13.0          0   \n",
       "69997        1132            YV       7058  ...    7.0     10.0          0   \n",
       "69998        2139            NW        641  ...   20.0     22.0          0   \n",
       "69999        1005            WN        510  ...    2.0     12.0          0   \n",
       "\n",
       "       CancellationCode  Diverted  CarrierDelay WeatherDelay NASDelay  \\\n",
       "0                   NaN         0           NaN          NaN      NaN   \n",
       "1                   NaN         0           NaN          NaN      NaN   \n",
       "2                   NaN         0           NaN          NaN      NaN   \n",
       "3                   NaN         0           NaN          NaN      NaN   \n",
       "4                   NaN         0           NaN          NaN      NaN   \n",
       "...                 ...       ...           ...          ...      ...   \n",
       "69995               NaN         0           NaN          NaN      NaN   \n",
       "69996               NaN         0           0.0          0.0      0.0   \n",
       "69997               NaN         0           NaN          NaN      NaN   \n",
       "69998               NaN         0           0.0          0.0     15.0   \n",
       "69999               NaN         0           NaN          NaN      NaN   \n",
       "\n",
       "       SecurityDelay  LateAircraftDelay  \n",
       "0                NaN                NaN  \n",
       "1                NaN                NaN  \n",
       "2                NaN                NaN  \n",
       "3                NaN                NaN  \n",
       "4                NaN                NaN  \n",
       "...              ...                ...  \n",
       "69995            NaN                NaN  \n",
       "69996            0.0               22.0  \n",
       "69997            NaN                NaN  \n",
       "69998            0.0                6.0  \n",
       "69999            NaN                NaN  \n",
       "\n",
       "[70000 rows x 29 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "df = pd.read_csv(\"2008.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.** Какая из причин отмены рейса (`CancellationCode`) была самой частой? (расшифровки кодов можно найти в описании данных)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CancellationCode'].mode()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.** Найдите среднее, минимальное и максимальное расстояние, пройденное самолетом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "724.5082571428571 4962 31\n"
     ]
    }
   ],
   "source": [
    "print(df['Distance'].mean(), df['Distance'].max(), df['Distance'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.** Не выглядит ли подозрительным минимальное пройденное расстояние? В какие дни и на каких рейсах оно было? Какое расстояние было пройдено этими же рейсами в другие дни?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Year  Month  DayofMonth  DayOfWeek  FlightNum  Distance\n",
      "1116   2008     12          30          2         65        31\n",
      "6958   2008     12          26          5         65        31\n",
      "17349  2008      8          18          1         64        31\n",
      "27534  2008      3          11          2         64        31\n",
      "46082  2008      8           9          6         65        31\n",
      "48112  2008      2          28          4         64        31\n",
      "       Distance  FlightNum\n",
      "501         533         64\n",
      "1116         31         65\n",
      "1389        680         64\n",
      "1517        680         65\n",
      "2619       2381         64\n",
      "...         ...        ...\n",
      "66529        82         65\n",
      "67172       533         64\n",
      "68264       386         65\n",
      "68338      2454         65\n",
      "69305      1005         65\n",
      "\n",
      "[78 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[df['Distance'] == df['Distance'].min()][['Year', 'Month', 'DayofMonth', 'DayOfWeek', 'FlightNum', 'Distance']])\n",
    "fl_numbs = df.loc[df['Distance'] == df['Distance'].min()]['FlightNum']\n",
    "print(df.loc[df['FlightNum'].isin(fl_numbs)][['Distance', 'FlightNum']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9.** Из какого аэропорта было произведено больше всего вылетов? В каком городе он находится?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ATL'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Origin'].value_counts().idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10.** Найдите для каждого аэропорта среднее время полета (`AirTime`) по всем вылетевшим из него рейсам. Какой аэропорт имеет наибольшее значение этого показателя?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origin\n",
      "ABE    88.266667\n",
      "ABI    36.400000\n",
      "ABQ    93.454321\n",
      "ABY    35.714286\n",
      "ACK    50.800000\n",
      "         ...    \n",
      "WRG    18.000000\n",
      "XNA    85.945736\n",
      "YAK    35.900000\n",
      "YKM    79.000000\n",
      "YUM    47.470588\n",
      "Name: AirTime, Length: 297, dtype: float64\n",
      "SJU\n"
     ]
    }
   ],
   "source": [
    "mean_time = df.groupby('Origin')['AirTime'].mean()\n",
    "print(mean_time)\n",
    "print(mean_time.idxmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11.** Найдите аэропорт, у которого наибольшая доля задержанных (`DepDelay > 0`) рейсов. Исключите при этом из рассмотрения аэропорты, из которых было отправлено меньше 1000 рейсов (используйте функцию `filter` после `groupby`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORD\n"
     ]
    }
   ],
   "source": [
    "grouped = df[df['DepDelay'] > 0].groupby('Origin')['DepDelay'].agg(['count', 'sum'])\n",
    "grouped = grouped[grouped['count'] > 1000]\n",
    "print(grouped['sum'].idxmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Линейная регрессия\n",
    "\n",
    "В этой части мы разберемся с линейной регрессией, способами её обучения и измерением качества ее прогнозов. \n",
    "\n",
    "Будем рассматривать датасет из предыдущей части задания для предсказания времени задержки отправления рейса в минутах (DepDelay). Отметим, что под задержкой подразумевается не только опоздание рейса относительно планируемого времени вылета, но и отправление до планируемого времени.\n",
    "\n",
    "### Подготовка данных\n",
    "\n",
    "**12.** Считайте выборку из файла при помощи функции pd.read_csv и ответьте на следующие вопросы:\n",
    "   - Имеются ли в данных пропущенные значения?\n",
    "   - Сколько всего пропущенных элементов в таблице \"объект-признак\"?\n",
    "   - Сколько объектов имеют хотя бы один пропуск?\n",
    "   - Сколько признаков имеют хотя бы одно пропущенное значение?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пропуски True\n",
      "Кол-во пропусков 353816\n",
      "Кол-во объектов имеют хотя бы один пропуск 70000\n",
      "Кол-во признаков которые имеют хотя бы одно пропущенное значение 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"2008.csv\")\n",
    "\n",
    "Y = df['DepDelay']\n",
    "X = df.drop('DepDelay', 1)\n",
    "print('Пропуски', X.isnull().any().any())\n",
    "print('Кол-во пропусков', X.isnull().sum().sum())\n",
    "print('Кол-во объектов имеют хотя бы один пропуск', X.isnull().any(axis=1).sum())\n",
    "print('Кол-во признаков которые имеют хотя бы одно пропущенное значение', X.isnull().any(axis=0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как вы понимаете, также не имеет смысла рассматривать при решении поставленной задачи объекты с пропущенным значением целевой переменной. В связи с этим ответьте на следующие вопросы и выполните соответствующие действия:\n",
    "- Имеются ли пропущенные значения в целевой переменной?\n",
    "- Проанализируйте объекты с пропущенными значениями целевой переменной. Чем вызвано это явление? Что их объединяет? Можно ли в связи с этим, на ваш взгляд, исключить какие-то признаки из рассмотрения? Обоснуйте свою точку зрения.\n",
    "\n",
    "Исключите из выборки объекты **с пропущенным значением целевой переменной и со значением целевой переменной, равным 0**, а также при необходимости исключите признаки в соответствии с вашим ответом на последний вопрос из списка и выделите целевую переменную в отдельный вектор, исключив её из матрицы \"объект-признак\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "кол-во пропусков у признаков:\n",
      " Year                     0\n",
      "Month                    0\n",
      "DayofMonth               0\n",
      "DayOfWeek                0\n",
      "DepTime                  0\n",
      "CRSDepTime               0\n",
      "ArrTime                140\n",
      "CRSArrTime               0\n",
      "UniqueCarrier            0\n",
      "FlightNum                0\n",
      "TailNum                  0\n",
      "ActualElapsedTime      164\n",
      "CRSElapsedTime           5\n",
      "AirTime                164\n",
      "ArrDelay               164\n",
      "Origin                   0\n",
      "Dest                     0\n",
      "Distance                 0\n",
      "TaxiIn                 140\n",
      "TaxiOut                  7\n",
      "Cancelled                0\n",
      "CancellationCode     63392\n",
      "Diverted                 0\n",
      "CarrierDelay         48538\n",
      "WeatherDelay         48538\n",
      "NASDelay             48538\n",
      "SecurityDelay        48538\n",
      "LateAircraftDelay    48538\n",
      "dtype: int64\n",
      "общее количество объектов 63404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  import sys\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/ipykernel_launcher.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"2008.csv\")\n",
    "\n",
    "df.dropna(subset = ['DepDelay'], inplace=True)\n",
    "df = df[df['DepDelay'] != 0]\n",
    "\n",
    "Y = df['DepDelay']\n",
    "X = df.drop('DepDelay', 1)\n",
    "\n",
    "print('кол-во пропусков у признаков:\\n', X.isnull().sum(axis=0))  \n",
    "print('общее количество объектов', str(len(df)))\n",
    "\n",
    "Y = df['DepDelay']\n",
    "X = df.drop(['Year', 'DepDelay', 'CancellationCode', 'CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay', 'TailNum'], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**13.** Обратите внимание, что признаки DepTime, CRSDepTime, ArrTime, CRSArrTime приведены в формате hhmm, в связи с чем будет не вполне корректно рассматривать их как вещественные.\n",
    "\n",
    "Преобразуйте каждый признак FeatureName из указанных в пару новых признаков FeatureName\\_Hour, FeatureName\\_Minute, разделив каждое из значений на часы и минуты. Не забудьте при этом исключить исходный признак из выборки. В случае, если значение признака отсутствует, значения двух новых признаков, его заменяющих, также должны отсутствовать. \n",
    "\n",
    "Например, признак DepTime необходимо заменить на пару признаков DepTime_Hour, DepTime_Minute. При этом, например, значение 155 исходного признака будет преобразовано в значения 1 и 55 признаков DepTime_Hour, DepTime_Minute соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Month  DayofMonth  DayOfWeek UniqueCarrier  FlightNum  \\\n",
      "0          6          18          3            WN        242   \n",
      "1          6           4          3            XE       2380   \n",
      "2          8           3          7            WN       1769   \n",
      "3          1          23          3            OO       3802   \n",
      "4          5           4          7            WN        399   \n",
      "...      ...         ...        ...           ...        ...   \n",
      "69994      1          26          6            OH       5218   \n",
      "69995      5          12          1            DL        794   \n",
      "69996      5          11          7            OO       6159   \n",
      "69998      2          18          1            NW        641   \n",
      "69999     12           6          6            WN        510   \n",
      "\n",
      "       ActualElapsedTime  CRSElapsedTime  AirTime  ArrDelay Origin  ...  \\\n",
      "0                   57.0            65.0     46.0       8.0    MDW  ...   \n",
      "1                  124.0           138.0    108.0       2.0    IAH  ...   \n",
      "2                  138.0           155.0    125.0     -19.0    MDW  ...   \n",
      "3                  102.0           111.0     79.0     -12.0    SLC  ...   \n",
      "4                  148.0           160.0    136.0     -17.0    LAS  ...   \n",
      "...                  ...             ...      ...       ...    ...  ...   \n",
      "69994              110.0           113.0     85.0      -8.0    CVG  ...   \n",
      "69995              128.0           129.0     86.0     -12.0    ORD  ...   \n",
      "69996               47.0            49.0     30.0      22.0    ORD  ...   \n",
      "69998              234.0           219.0    192.0      21.0    RSW  ...   \n",
      "69999               60.0            65.0     46.0      -6.0    LAS  ...   \n",
      "\n",
      "      Cancelled  Diverted  DepTime_Hour  DepTime_Minute  CRSDepTime_Hour  \\\n",
      "0             0         0        2100.0            11.0             2000   \n",
      "1             0         0        1400.0            26.0             1400   \n",
      "2             0         0        1100.0            43.0             1100   \n",
      "3             0         0        1100.0            41.0             1100   \n",
      "4             0         0         800.0            15.0              800   \n",
      "...         ...       ...           ...             ...              ...   \n",
      "69994         0         0         900.0            20.0              900   \n",
      "69995         0         0        1800.0            29.0             1800   \n",
      "69996         0         0        1100.0            49.0             1100   \n",
      "69998         0         0        1900.0             6.0             1900   \n",
      "69999         0         0         800.0            59.0              900   \n",
      "\n",
      "       CRSDepTime_Minute  ArrTime_Hour  ArrTime_Minute  CRSArrTime_Hour  \\\n",
      "0                     55        2300.0             8.0             2300   \n",
      "1                     10        1700.0            30.0             1700   \n",
      "2                     45        1500.0             1.0             1500   \n",
      "3                     44        1300.0            23.0             1300   \n",
      "4                     20        1200.0            43.0             1300   \n",
      "...                  ...           ...             ...              ...   \n",
      "69994                 25        1100.0            10.0             1100   \n",
      "69995                 40        2100.0            37.0             2100   \n",
      "69996                 25        1300.0            36.0             1300   \n",
      "69998                  0        2200.0             0.0             2100   \n",
      "69999                  0         900.0            59.0             1000   \n",
      "\n",
      "       CRSArrTime_Minute  \n",
      "0                      0  \n",
      "1                     28  \n",
      "2                     20  \n",
      "3                     35  \n",
      "4                      0  \n",
      "...                  ...  \n",
      "69994                 18  \n",
      "69995                 49  \n",
      "69996                 14  \n",
      "69998                 39  \n",
      "69999                  5  \n",
      "\n",
      "[63404 rows x 24 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "features_name = ['DepTime', 'CRSDepTime', 'ArrTime', 'CRSArrTime']\n",
    "for feature_name in features_name:\n",
    "    X[feature_name + '_Hour'] = X[feature_name] - X[feature_name] % 100\n",
    "    X[feature_name + '_Minute'] = X[feature_name] % 100\n",
    "X = X.drop(features_name, 1)\n",
    "\n",
    "X.head(10).style \n",
    "print(X)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**14.** Некоторые из признаков, отличных от целевой переменной, могут оказывать чересчур значимое влияние на прогноз, поскольку по своему смыслу содержат большую долю информации о значении целевой переменной. Изучите описание датасета и исключите признаки, сильно коррелирующие с ответами. Ваш выбор признаков для исключения из выборки обоснуйте. Кроме того, исключите признаки TailNum и Year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X = X.drop(['CRSDepTime_Minute', 'CRSDepTime_Hour', 'CRSArrTime_Hour', 'CRSArrTime_Minute'], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**15.** Приведем данные к виду, пригодному для обучения линейных моделей. Для этого вещественные признаки надо отмасштабировать, а категориальные — привести к числовому виду. Также надо устранить пропуски в данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первую очередь поймем, зачем необходимо применять масштабирование. Следующие ячейки с кодом построят гистограммы для 3 вещественных признаков выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7b24cea8d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X['DepTime_Hour'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7b24b51e50>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X['TaxiIn'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7b25d80c90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X['FlightNum'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какую проблему вы наблюдаете на этих графиках? Как масштабирование поможет её исправить?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторые из признаков в нашем датасете являются категориальными. Типичным подходом к работе с ними является бинарное, или [one-hot-кодирование](https://en.wikipedia.org/wiki/One-hot).\n",
    "\n",
    "Реализуйте функцию transform_data, которая принимает на вход DataFrame с признаками и выполняет следующие шаги:\n",
    "1. Замена пропущенных значений на нули для вещественных признаков и на строки 'nan' для категориальных.\n",
    "2. Масштабирование вещественных признаков с помощью [StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html).\n",
    "3. One-hot-кодирование категориальных признаков с помощью [DictVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html) или функции [pd.get_dummies](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html).\n",
    "\n",
    "Метод должен возвращать преобразованный DataFrame, который должна состоять из масштабированных вещественных признаков и закодированных категориальных (исходные признаки должны быть исключены из выборки)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "def transform_data(data):\n",
    "    cat_features_mask = (data.dtypes == \"object\").values\n",
    "    label_enc = preprocessing.LabelEncoder()\n",
    "    for feature in data.columns[cat_features_mask]:\n",
    "        data[feature] = label_enc.fit_transform(data[feature])\n",
    "\n",
    "    enc = preprocessing.OneHotEncoder(sparse=False)\n",
    "    data_str = enc.fit_transform(data[data.columns[cat_features_mask]])\n",
    "    data_str = pd.DataFrame(data=data_str)\n",
    "\n",
    "    data_str.drop(enc.feature_indices_[:-1], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    data_real = data[data.columns[~cat_features_mask]]\n",
    "\n",
    "    data_str.fillna('nan', inplace=True)\n",
    "    data_real = data_real.fillna(0)\n",
    "    normalizer = preprocessing.StandardScaler().fit_transform(data_real)\n",
    "    data_real = pd.DataFrame(data=normalizer)\n",
    "\n",
    "\n",
    "    data = pd.concat([data_real, data_str], axis=1)\n",
    "    data.columns = np.array([\"f\"+str(i) for i in range(1, data.shape[1] + 1)])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примените функцию transform_data к данным. Сколько признаков получилось после преобразования?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:395: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  check_array(X, dtype=np.int)\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:550: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X = check_array(X, dtype=np.int)\n",
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/utils/deprecation.py:100: DeprecationWarning: The ``feature_indices_`` attribute was deprecated in version 0.20 and will be removed 0.22.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f619</th>\n",
       "      <th>f620</th>\n",
       "      <th>f621</th>\n",
       "      <th>f622</th>\n",
       "      <th>f623</th>\n",
       "      <th>f624</th>\n",
       "      <th>f625</th>\n",
       "      <th>f626</th>\n",
       "      <th>f627</th>\n",
       "      <th>f628</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.118281</td>\n",
       "      <td>0.256485</td>\n",
       "      <td>-0.462767</td>\n",
       "      <td>-0.991600</td>\n",
       "      <td>-0.988979</td>\n",
       "      <td>-0.916826</td>\n",
       "      <td>-0.849307</td>\n",
       "      <td>-0.021975</td>\n",
       "      <td>-0.744130</td>\n",
       "      <td>-0.786908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.118281</td>\n",
       "      <td>-1.332050</td>\n",
       "      <td>-0.462767</td>\n",
       "      <td>0.106546</td>\n",
       "      <td>-0.040552</td>\n",
       "      <td>0.127377</td>\n",
       "      <td>0.064301</td>\n",
       "      <td>-0.175419</td>\n",
       "      <td>0.183961</td>\n",
       "      <td>-0.582387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.467662</td>\n",
       "      <td>-1.445517</td>\n",
       "      <td>1.541454</td>\n",
       "      <td>-0.207284</td>\n",
       "      <td>0.157627</td>\n",
       "      <td>0.370547</td>\n",
       "      <td>0.314806</td>\n",
       "      <td>-0.712473</td>\n",
       "      <td>0.471018</td>\n",
       "      <td>-0.582387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.583137</td>\n",
       "      <td>0.823819</td>\n",
       "      <td>-0.462767</td>\n",
       "      <td>0.836931</td>\n",
       "      <td>-0.351976</td>\n",
       "      <td>-0.258835</td>\n",
       "      <td>-0.363032</td>\n",
       "      <td>-0.533455</td>\n",
       "      <td>-0.347886</td>\n",
       "      <td>-0.582387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.411252</td>\n",
       "      <td>-1.332050</td>\n",
       "      <td>1.541454</td>\n",
       "      <td>-0.910960</td>\n",
       "      <td>0.299183</td>\n",
       "      <td>0.442068</td>\n",
       "      <td>0.476898</td>\n",
       "      <td>-0.661325</td>\n",
       "      <td>0.634799</td>\n",
       "      <td>-0.582387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63399</th>\n",
       "      <td>-1.583137</td>\n",
       "      <td>1.164220</td>\n",
       "      <td>1.040399</td>\n",
       "      <td>1.564234</td>\n",
       "      <td>-0.238731</td>\n",
       "      <td>-0.230227</td>\n",
       "      <td>-0.274618</td>\n",
       "      <td>-0.431159</td>\n",
       "      <td>-0.120706</td>\n",
       "      <td>1.053782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63400</th>\n",
       "      <td>-0.411252</td>\n",
       "      <td>-0.424316</td>\n",
       "      <td>-1.464878</td>\n",
       "      <td>-0.708075</td>\n",
       "      <td>0.016071</td>\n",
       "      <td>-0.001361</td>\n",
       "      <td>-0.259882</td>\n",
       "      <td>-0.533455</td>\n",
       "      <td>-0.217566</td>\n",
       "      <td>3.098994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63401</th>\n",
       "      <td>-0.411252</td>\n",
       "      <td>-0.537783</td>\n",
       "      <td>1.541454</td>\n",
       "      <td>2.047563</td>\n",
       "      <td>-1.130535</td>\n",
       "      <td>-1.145693</td>\n",
       "      <td>-1.085076</td>\n",
       "      <td>0.336062</td>\n",
       "      <td>-1.043514</td>\n",
       "      <td>-0.582387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63402</th>\n",
       "      <td>-1.290166</td>\n",
       "      <td>0.256485</td>\n",
       "      <td>-1.464878</td>\n",
       "      <td>-0.786661</td>\n",
       "      <td>1.516567</td>\n",
       "      <td>1.286013</td>\n",
       "      <td>1.302092</td>\n",
       "      <td>0.310488</td>\n",
       "      <td>1.208912</td>\n",
       "      <td>2.689951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63403</th>\n",
       "      <td>1.639547</td>\n",
       "      <td>-1.105117</td>\n",
       "      <td>1.040399</td>\n",
       "      <td>-0.853947</td>\n",
       "      <td>-0.946512</td>\n",
       "      <td>-0.916826</td>\n",
       "      <td>-0.849307</td>\n",
       "      <td>-0.380011</td>\n",
       "      <td>-0.892061</td>\n",
       "      <td>-0.991430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63404 rows × 628 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             f1        f2        f3        f4        f5        f6        f7  \\\n",
       "0     -0.118281  0.256485 -0.462767 -0.991600 -0.988979 -0.916826 -0.849307   \n",
       "1     -0.118281 -1.332050 -0.462767  0.106546 -0.040552  0.127377  0.064301   \n",
       "2      0.467662 -1.445517  1.541454 -0.207284  0.157627  0.370547  0.314806   \n",
       "3     -1.583137  0.823819 -0.462767  0.836931 -0.351976 -0.258835 -0.363032   \n",
       "4     -0.411252 -1.332050  1.541454 -0.910960  0.299183  0.442068  0.476898   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "63399 -1.583137  1.164220  1.040399  1.564234 -0.238731 -0.230227 -0.274618   \n",
       "63400 -0.411252 -0.424316 -1.464878 -0.708075  0.016071 -0.001361 -0.259882   \n",
       "63401 -0.411252 -0.537783  1.541454  2.047563 -1.130535 -1.145693 -1.085076   \n",
       "63402 -1.290166  0.256485 -1.464878 -0.786661  1.516567  1.286013  1.302092   \n",
       "63403  1.639547 -1.105117  1.040399 -0.853947 -0.946512 -0.916826 -0.849307   \n",
       "\n",
       "             f8        f9       f10  ...  f619  f620  f621  f622  f623  f624  \\\n",
       "0     -0.021975 -0.744130 -0.786908  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "1     -0.175419  0.183961 -0.582387  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2     -0.712473  0.471018 -0.582387  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "3     -0.533455 -0.347886 -0.582387  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "4     -0.661325  0.634799 -0.582387  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "...         ...       ...       ...  ...   ...   ...   ...   ...   ...   ...   \n",
       "63399 -0.431159 -0.120706  1.053782  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "63400 -0.533455 -0.217566  3.098994  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "63401  0.336062 -1.043514 -0.582387  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "63402  0.310488  1.208912  2.689951  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "63403 -0.380011 -0.892061 -0.991430  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "       f625  f626  f627  f628  \n",
       "0       0.0   0.0   0.0   0.0  \n",
       "1       0.0   0.0   0.0   0.0  \n",
       "2       0.0   0.0   0.0   0.0  \n",
       "3       0.0   0.0   0.0   0.0  \n",
       "4       0.0   0.0   0.0   0.0  \n",
       "...     ...   ...   ...   ...  \n",
       "63399   0.0   0.0   0.0   0.0  \n",
       "63400   0.0   0.0   0.0   0.0  \n",
       "63401   0.0   0.0   0.0   0.0  \n",
       "63402   0.0   0.0   0.0   0.0  \n",
       "63403   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[63404 rows x 628 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = transform_data(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**16. (0.5 балла)** Разбейте выборку и вектор целевой переменной на обучение и контроль в отношении 70/30 (для этого можно использовать, например, функцию [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47629     5.0\n",
       "39632    15.0\n",
       "46373    99.0\n",
       "42942    16.0\n",
       "44966    79.0\n",
       "         ... \n",
       "69067     1.0\n",
       "42174    10.0\n",
       "963      -3.0\n",
       "17511     1.0\n",
       "62292    -5.0\n",
       "Name: DepDelay, Length: 44382, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30, random_state=42)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-learn\n",
    "\n",
    "<img src = \"https://pp.vk.me/c4534/u35727827/93547647/x_d31c4463.jpg\">\n",
    "Теперь, когда мы привели данные к пригодному виду, попробуем решить задачу при помощи метода наименьших квадратов. Напомним, что данный метод заключается в оптимизации функционала $MSE$:\n",
    "\n",
    "$$MSE(X, y) = \\frac{1}{l} \\sum_{i=1}^l (<w, x_i> - y_i)^2 \\to \\min_{w},$$\n",
    "\n",
    "где $\\{ (x_i, y_i ) \\}_{i=1}^l$ — обучающая выборка, состоящая из $l$ пар объект-ответ.\n",
    "\n",
    "Заметим, что решение данной задачи уже реализовано в модуле sklearn в виде класса [LinearRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression).\n",
    "\n",
    "**17.** Обучите линейную регрессию на 1000 объектах из обучающей выборки и выведите значения $MSE$ и $R^2$ на этой подвыборке и контрольной выборке (итого 4 различных числа). Проинтерпретируйте полученный результат — насколько качественные прогнозы строит полученная модель? Какие проблемы наблюдаются в модели?\n",
    "\n",
    "**Подсказка**: изучите значения полученных коэффициентов $w$, сохраненных в атрибуте coef_ объекта LinearRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression as LR\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "lr = LR()\n",
    "X_tr = X_train[:1000]\n",
    "y_tr = y_train[:1000]\n",
    "X_ts = X_test[:1000]\n",
    "y_ts = y_test[:1000]\n",
    "\n",
    "lr.fit(X_tr, y_tr)\n",
    "\n",
    "y_pred = lr.predict(X_ts)\n",
    "y_pr = lr.predict(X_tr)\n",
    "\n",
    "print(r2_score(y_ts, y_pred), r2_score(y_tr, y_pr))\n",
    "print(mean_squared_error(y_ts, y_pred, ), mean_squared_error(y_tr, y_pr))\n",
    "print('coeff', lr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для решения описанных вами в предыдущем пункте проблем используем L1- или L2-регуляризацию, тем самым получив Lasso и Ridge регрессии соответственно и изменив оптимизационную задачу одним из следующих образов:\n",
    "$$MSE_{L1}(X, y) = \\frac{1}{l} \\sum_{i=1}^l (<w, x_i> - y_i)^2 + \\alpha ||w||_1 \\to \\min_{w},$$\n",
    "$$MSE_{L2}(X, y) = \\frac{1}{l} \\sum_{i=1}^l (<w, x_i> - y_i)^2 + \\alpha ||w||_2^2 \\to \\min_{w},$$\n",
    "\n",
    "где $\\alpha$ — коэффициент регуляризации. Один из способов его подбора заключается в переборе некоторого количества значений и оценке качества на кросс-валидации для каждого из них, после чего выбирается значение, для которого было получено наилучшее качество.\n",
    "\n",
    "**18.** Обучите линейные регрессии с L1- и L2-регуляризатором, подобрав лучшее значение параметра регуляризации из списка alpha_grid при помощи кросс-валидации c 5 фолдами на тех же 1000 объектах, что и в п.17. Выведите значения $MSE$ и $R^2$ на обучающей и контрольной выборках. Удалось ли решить указанные вами ранее проблемы?\n",
    "\n",
    "Для выполнения данного задания вам могут понадобиться реализованные в библиотеке объекты [LassoCV](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html), [RidgeCV](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html) и [KFold](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.KFold.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Градиентный спуск\n",
    "\n",
    "В предыдущем разделе мы использовали существующие реализации методов обучения линейной регрессии с регуляризацией и без. Тем не менее, подобные реализации, как правило, имеются лишь для ограниченного набора стандартных методов. В частности, при выходе функционала качества за пределы стандартного множества необходимо самостоятельно реализовывать составляющие процесса решения оптимизационной задачи. Именно этому и посвящен данный раздел задания.\n",
    "\n",
    "Пусть необходимо минимизировать следующий функционал (Mean Square Percentage Error — модифицированный [RMSPE](https://www.kaggle.com/c/rossmann-store-sales/details/evaluation)):\n",
    "$$MSPE(\\{x_i, y_i\\}_{i=1}^l, \\, w) = \\frac{1}{l}\\sum_{i=1}^l \\left( \\frac{y_i - \\langle w, x_i \\rangle }{y_i} \\right)^2,$$\n",
    "\n",
    "где $\\{x_i, y_i\\}_{i=1}^l$ — обучающая выборка, $w$ — вектор весов линейной модели. Будем также рассматривать функционал $MSPE$ с L2-регуляризацией:\n",
    "\n",
    "$$MSPE(\\{x_i, y_i\\}_{i=1}^l, \\, w) = \\frac{1}{l}\\sum_{i=1}^l \\left( \\frac{y_i - \\langle w, x_i \\rangle }{y_i} \\right)^2 + ||w||_2^2.$$\n",
    "\n",
    "**19.** Добавьте к объектам обеих выборок из п. 16 единичный признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**20.** Реализуйте функции, которые вычисляют:\n",
    " * прогнозы линейной модели;\n",
    " * функционал $MSPE$ и его градиент;\n",
    " * регуляризованный $MSPE$ и его градиент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# возвращает вектор прогнозов линейной модели с вектором весов w для выборки X\n",
    "def make_pred(X, w):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# возвращает значение функционала MSPE для выборки (X, y) и вектора весов w\n",
    "def get_func(w, X, y):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# возвращает градиент функционала MSPE для выборки (X, y) и вектора весов w\n",
    "def get_grad(w, X, y):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# возвращает значение регуляризованного функционала MSPE для выборки (X, y) и вектора весов w\n",
    "def get_reg_func(w, X, y):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# возвращает градиент регуляризованного функционала MSPE для выборки (X, y) и вектора весов w\n",
    "def get_reg_grad(w, X, y):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**21.** Реализуйте метод градиентного спуска для описанных функционалов ($MSPE$ и его регуляризованный вариант). Функция должна принимать следующие параметры:\n",
    " - X — матрица \"объект-признак\";\n",
    " - y — вектор целевой переменной;\n",
    " - w0 — начальное значение вектора весов;\n",
    " - step_size — значение темпа обучения;\n",
    " - max_iter — максимальное число итераций;\n",
    " - eps — значение, используемое в критерии останова;\n",
    " - is_reg — бинарный параметр, принимает значение True в случае наличия регуляризации функционала, False — в противном случае.\n",
    " \n",
    "Процесс должен быть остановлен, если выполнено хотя бы одно из следующих условий:\n",
    " - было выполнено заданное количество итераций max_iter;\n",
    " - евклидова норма разности векторов $w$ на соседних итерациях стала меньше, чем eps.\n",
    "\n",
    "Функция должна возвращать полученный в результате оптимизации вектор $w$ и список значений функционала на каждой итерации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def grad_descent(X, y, step_size, max_iter, eps, is_reg):\n",
    "    # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите линейную регрессию с функционалом $MSPE$ на обучающей выборке при помощи метода градиентного спуска и изобразите кривые зависимости значения функционала от номера итерации для различных:\n",
    " * значений размера шага из набора [0.001, 1, 10];\n",
    " * способов начальной инициализации вектора весов (нули, случайные веса).\n",
    "\n",
    "Проанализируйте полученные результаты — влияют ли данные параметры на скорость сходимости и итоговое качество? Если да, то как?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**22.** Обучите линейную регрессию с функционалом MSPE и его регуляризованным вариантом на обучающей выборке при помощи метода градиентного спуска и изобразите кривые зависимости значения функционала от номера итерации. Исследуйте зависимость скорости сходимости от наличия регуляризации. Обоснуйте, почему так происходит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод градиентного спуска может быть весьма трудозатратен в случае большого размера обучающей выборки. Поэтому часто используют метод стохастического градиентного спуска, где на каждой итерации выбирается случайный объект из обучающей выборки и обновление весов происходит только по этому объекту. \n",
    "\n",
    "**23.**  Реализуйте метод стохастического градиентного спуска (SGD) для описанных функционалов ($MSPE$ и его регуляризованный вариант). Функция должна иметь параметры и возвращаемое значение, аналогичные оным функции grad\\_descent из п.21. Кроме того, должен использоваться аналогичный критерий останова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def sgd(X, y, step_size, max_iter, eps, is_reg):\n",
    "    # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите линейную регрессию с функционалом $MSPE$ и его регуляризованным вариантом на обучающей выборке при помощи метода стохастического градиентного спуска, подобрав при этом размер шага, при котором метод будет сходиться. Нарисуйте график сходимости. Выведите значения $MSPE, MSE, R^2$ на контрольной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**24.** Аналогично п.22 исследуйте зависимость скорости сходимости метода SGD от наличия регуляризации. Обоснуйте, почему так происходит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**25.** Обучите стандартную линейную регрессию с функционалом качества MSE на обучающей выборке и выведите значение MSPE полученного решения на контрольной выборке. Как оно соотносится с аналогичным результатом для решения, полученного в п.22? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
